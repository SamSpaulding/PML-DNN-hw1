{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/samuelsp/projects/PML-DNN-hw1/neural_net\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import personalized_neural_net\n",
    "print(os.getcwd())\n",
    "%pylab inline\n",
    "\n",
    "reload(personalized_neural_net)\n",
    "personalized_neural_net.reload_files()\n",
    "\n",
    "dropbox_path = '/Users/samuelsp/projects/PML-DNN-hw1/'\n",
    "filename = 'parkinsons_supervised.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping normalization for subject_num\n",
      "Original data length was 5875\n",
      "After dropping rows with nan in any label column, length is 5875\n",
      "3581 rows in training data\n",
      "val!\n",
      "(array([[  6.00000000e+00,  -2.02615874e-01,  -6.84709360e-01, ...,\n",
      "         -4.00589494e-02,   9.71214167e-01,   5.81883230e-01],\n",
      "       [  4.00000000e+00,   1.03767036e+00,  -6.84709360e-01, ...,\n",
      "          1.58793837e+00,  -5.25717842e-01,  -6.17290817e-01],\n",
      "       [  1.50000000e+01,   2.28907133e-02,  -6.84709360e-01, ...,\n",
      "         -3.93037176e-01,  -9.39930448e-01,  -1.22215280e+00],\n",
      "       ..., \n",
      "       [  8.00000000e+00,   9.24917062e-01,   1.46047368e+00, ...,\n",
      "         -1.13157779e+00,   4.39559277e-01,  -5.80036418e-01],\n",
      "       [  2.60000000e+01,  -1.78116198e+00,  -6.84709360e-01, ...,\n",
      "          1.17301998e+00,   2.25336823e-02,   1.97140897e-01],\n",
      "       [  7.00000000e+00,   8.12163768e-01,  -6.84709360e-01, ...,\n",
      "          5.67035355e-01,  -8.37959603e-01,  -3.07606756e-01]]), array([[ 26.806,  39.597],\n",
      "       [ 17.983,  26.983],\n",
      "       [ 15.   ,  20.189],\n",
      "       ..., \n",
      "       [ 21.486,  27.486],\n",
      "       [ 24.332,  30.553],\n",
      "       [ 17.681,  24.617]]))\n",
      "1167 rows in validation data\n",
      "1127 rows in testing data\n",
      "\n",
      "Performing regression.\n",
      "Input dimensions (number of features): 20\n",
      "Number of classes/outputs: 2\n",
      "\n",
      "Building computation graph...\n",
      "last non-personalized layer size was\n",
      "32\n",
      "Okay, making a neural net with the following structure:\n",
      "Non-Personalized Layers:\n",
      "[('20x128', '128'), ('128x64', '64'), ('64x32', '32')]\n",
      "Personalized Layers:\n",
      "(42, 32, 8)\n",
      " and \n",
      "(42, 8, 2)\n",
      "TF_X shape\n",
      "<unknown>\n",
      "hidden1 has shape\n",
      "(?, 128)\n",
      "hidden2 has shape\n",
      "(?, 64)\n",
      "hidden3 has shape\n",
      "(?, 32)\n",
      "returning output of hidden5!\n",
      "Training iteration 0\n",
      "\t Training RMSE 20.0985\n",
      "\t Validation RMSE 21.1929\n",
      "\t Loss 22.9203\n",
      "Training iteration 10000\n",
      "\t Training RMSE 2.29149\n",
      "\t Validation RMSE 1.12218\n",
      "\t Loss 1.75746\n",
      "Training iteration 20000\n",
      "\t Training RMSE 2.64175\n",
      "\t Validation RMSE 2.91052\n",
      "\t Loss 3.3628\n",
      "Training iteration 30000\n",
      "\t Training RMSE 2.74212\n",
      "\t Validation RMSE 2.35065\n",
      "\t Loss 2.68335\n",
      "Training iteration 40000\n",
      "\t Training RMSE 1.71851\n",
      "\t Validation RMSE 1.28763\n",
      "\t Loss 1.60909\n",
      "(26, 20)\n",
      "(26, 2)\n",
      "1.11207\n",
      "(23, 20)\n",
      "(23, 2)\n",
      "0.725549\n",
      "(33, 20)\n",
      "(33, 2)\n",
      "1.18828\n",
      "(34, 20)\n",
      "(34, 2)\n",
      "1.02518\n",
      "(31, 20)\n",
      "(31, 2)\n",
      "1.07364\n",
      "(28, 20)\n",
      "(28, 2)\n",
      "1.46375\n",
      "(33, 20)\n",
      "(33, 2)\n",
      "1.09328\n",
      "(28, 20)\n",
      "(28, 2)\n",
      "0.910289\n",
      "(38, 20)\n",
      "(38, 2)\n",
      "0.458624\n",
      "(31, 20)\n",
      "(31, 2)\n",
      "0.860196\n",
      "(27, 20)\n",
      "(27, 2)\n",
      "1.81268\n",
      "(20, 20)\n",
      "(20, 2)\n",
      "0.874146\n",
      "(25, 20)\n",
      "(25, 2)\n",
      "0.831237\n",
      "(33, 20)\n",
      "(33, 2)\n",
      "1.76182\n",
      "(29, 20)\n",
      "(29, 2)\n",
      "0.823915\n",
      "(27, 20)\n",
      "(27, 2)\n",
      "0.749002\n",
      "(34, 20)\n",
      "(34, 2)\n",
      "2.72791\n",
      "(27, 20)\n",
      "(27, 2)\n",
      "0.348908\n",
      "(31, 20)\n",
      "(31, 2)\n",
      "0.737761\n",
      "(21, 20)\n",
      "(21, 2)\n",
      "0.397447\n",
      "(28, 20)\n",
      "(28, 2)\n",
      "3.04892\n",
      "(30, 20)\n",
      "(30, 2)\n",
      "1.05445\n",
      "(22, 20)\n",
      "(22, 2)\n",
      "1.00828\n",
      "(27, 20)\n",
      "(27, 2)\n",
      "0.499428\n",
      "(28, 20)\n",
      "(28, 2)\n",
      "1.57302\n",
      "(23, 20)\n",
      "(23, 2)\n",
      "1.86174\n",
      "(20, 20)\n",
      "(20, 2)\n",
      "0.754873\n",
      "(20, 20)\n",
      "(20, 2)\n",
      "1.56211\n",
      "(33, 20)\n",
      "(33, 2)\n",
      "2.31574\n",
      "(20, 20)\n",
      "(20, 2)\n",
      "1.0991\n",
      "(20, 20)\n",
      "(20, 2)\n",
      "2.57911\n",
      "(17, 20)\n",
      "(17, 2)\n",
      "1.83308\n",
      "(27, 20)\n",
      "(27, 2)\n",
      "1.22374\n",
      "(26, 20)\n",
      "(26, 2)\n",
      "1.47875\n",
      "(45, 20)\n",
      "(45, 2)\n",
      "1.05292\n",
      "(27, 20)\n",
      "(27, 2)\n",
      "1.54113\n",
      "(31, 20)\n",
      "(31, 2)\n",
      "4.52116\n",
      "(29, 20)\n",
      "(29, 2)\n",
      "0.612034\n",
      "(22, 20)\n",
      "(22, 2)\n",
      "0.611513\n",
      "(28, 20)\n",
      "(28, 2)\n",
      "0.912238\n",
      "(35, 20)\n",
      "(35, 2)\n",
      "1.31244\n",
      "(30, 20)\n",
      "(30, 2)\n",
      "1.25847\n",
      "Final RMSE on validation data is: 1.30214\n",
      "[1.1120697, 0.7255488, 1.1882772, 1.0251832, 1.0736371, 1.4637495, 1.0932779, 0.91028917, 0.45862359, 0.8601957, 1.8126839, 0.87414646, 0.83123708, 1.7618182, 0.82391542, 0.74900216, 2.7279129, 0.34890801, 0.73776102, 0.39744675, 3.0489218, 1.0544524, 1.0082804, 0.49942762, 1.5730178, 1.8617412, 0.75487304, 1.562112, 2.3157425, 1.0990984, 2.5791137, 1.833084, 1.2237357, 1.4787544, 1.0529248, 1.541128, 4.5211563, 0.61203355, 0.61151326, 0.91223842, 1.3124415, 1.2584654]\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [128,64,32]\n",
    "learning_rate = 0.01\n",
    "weight_penalty = 0.01\n",
    "dropout_prob = 0.9\n",
    "batch_size = 25\n",
    "clip_gradients = True\n",
    "results_dict = {}\n",
    "\n",
    "for i in range(0, 1):\n",
    "    net = personalized_neural_net.NeuralNetwork(dropbox_path + filename, 'homework', \n",
    "                               layer_sizes, batch_size, learning_rate, dropout_prob, \n",
    "                               weight_penalty, clip_gradients, model_type='regression')\n",
    "\n",
    "    net.train(num_steps=50000, output_every_nth=10000)\n",
    "    results_dict[(str(layer_sizes[0]) + \"x\" + str(layer_sizes[1]), learning_rate, weight_penalty, dropout_prob, i)] = net.test_on_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#find good hyperparameters for the base set\n",
    "\n",
    "layer_size_cands = [[64, 32], [128, 64, 32], [32, 32, 32], [32, 16, 8]]\n",
    "learning_rates = [0.01, .1]\n",
    "weight_penalties = [0.01, .05]\n",
    "dropouts = [0.9, .8]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def search_for_HPs():\n",
    "    rmse_results = []\n",
    "    dict = {}\n",
    "    import time\n",
    "    start = time.time()\n",
    "    index = 0\n",
    "    for learning_rate in learning_rates:\n",
    "        for weight_penalty in weight_penalties:\n",
    "            for dropout_prob in dropouts:\n",
    "                for i in range(0,5):\n",
    "                    clip_gradients = True\n",
    "                    print('this is iteration ' + str(i) + ' !!!!!')\n",
    "                    net = neural_net.NeuralNetwork(dropbox_path + filename, 'homework', \n",
    "                                               layer_size_cands[index], batch_size, learning_rate, dropout_prob, \n",
    "                                               weight_penalty, clip_gradients, model_type='regression')\n",
    "                    net.train(num_steps=50000, output_every_nth=10000)\n",
    "                    dict[(str(layer_size_cands[index][0]) + \"x\" + str(layer_size_cands[index][1]), learning_rate, weight_penalty, dropout_prob, i)] = net.test_on_validation()\n",
    "\n",
    "    end = time.time()\n",
    "    print end-start\n",
    "    net.plot_training_progress()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### debugging neural network using session.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.35033551, -1.78116202, -0.68470937, -1.40052152, -0.30320659,\n",
      "        -0.1525038 , -0.25575474, -0.20323569, -0.25678062,  0.96460992,\n",
      "         0.52912575,  0.97140121,  1.18462873,  0.82155502,  0.97114718,\n",
      "        -0.20225847, -0.40879247,  1.4391408 ,  0.14954013, -0.16320474],\n",
      "       [-0.62218499, -0.76638234,  1.46047366,  0.49315697, -0.65916598,\n",
      "        -0.88036144, -0.54216307, -0.54065609, -0.54115933, -0.91260463,\n",
      "        -0.95570928, -0.86152756, -0.82540822, -0.99184608, -0.86126816,\n",
      "        -0.48749965,  1.05310428, -2.19696879,  0.07246424, -1.14588571],\n",
      "       [ 0.4313789 , -0.87913561,  1.46047366, -1.33126593, -0.18627307,\n",
      "        -0.4621276 , -0.04247193, -0.14307547, -0.0434966 ,  0.47931957,\n",
      "         0.38813251,  0.52619565,  0.54269242,  0.58743757,  0.52594227,\n",
      "        -0.46723726,  0.82877713, -1.87455714,  1.49147642, -0.31518951],\n",
      "       [-0.70322841,  0.92491704,  1.46047366, -0.54672247, -0.43217739,\n",
      "        -0.71460325, -0.29841128, -0.35755974, -0.2984218 , -0.50852293,\n",
      "        -0.54154164, -0.40329537, -0.48849687, -0.57709491, -0.40354744,\n",
      "        -0.30525616,  0.3612718 , -0.7216025 , -1.23093414, -1.05796969],\n",
      "       [ 0.99868256, -0.65362906, -0.68470937, -1.01195133, -0.05214344,\n",
      "         0.42438021, -0.24661404, -0.07245259, -0.2456086 , -0.21507327,\n",
      "        -0.29039744, -0.40942556, -0.23581339,  0.12677111, -0.40916678,\n",
      "        -0.1134883 , -0.28225496,  1.69729197,  0.77528948,  0.14812773],\n",
      "       [ 0.4313789 , -0.87913561,  1.46047366,  0.88773161, -0.35995373,\n",
      "        -0.61253256, -0.43552166, -0.38110068, -0.43553296, -0.43947592,\n",
      "        -0.47985709, -0.41862085, -0.38020396, -0.41513005, -0.41836208,\n",
      "        -0.43581539,  1.48903418,  0.24280785,  0.97909051, -0.36442247],\n",
      "       [-0.29801151,  0.02289071, -0.68470937,  0.43758833, -0.15703969,\n",
      "        -0.02086393, -0.00286226, -0.17707907, -0.00388671,  0.13486934,\n",
      "         0.07970981,  0.29324821,  0.06078889,  0.13333043,  0.29299515,\n",
      "        -0.36134017,  0.23850451, -0.80997318, -0.2570774 , -0.34244347],\n",
      "       [-0.62218499, -0.76638234,  1.46047366, -1.4646492 , -0.27053398,\n",
      "        -0.52268761, -0.17044161, -0.28170556, -0.16943574, -0.90083522,\n",
      "        -0.93808514, -0.84390324, -0.8061561 , -0.98175478, -0.84364384,\n",
      "        -0.37314022,  0.55331659, -1.95768201, -0.15918539, -1.02950692],\n",
      "       [-0.46009827,  0.02289071, -0.68470937, -0.71697134, -0.13296513,\n",
      "         0.02007806, -0.10340987, -0.27385855, -0.10240362, -0.75567967,\n",
      "        -0.7970919 , -0.74888521, -0.71952176, -0.90354747, -0.74888134,\n",
      "        -0.25077358,  0.26041883, -0.40080491,  0.21634862,  0.55309075],\n",
      "       [-0.13592476,  0.24839731, -0.68470937,  0.18510531,  0.29693753,\n",
      "         0.58757955,  0.25003022,  0.17341962,  0.24900721,  0.58995163,\n",
      "         0.92126316,  0.63653922,  0.5884161 ,  0.31194589,  0.63679653,\n",
      "        -0.11508974, -0.2593981 ,  0.59558433,  0.60763538,  0.32044306]], dtype=float32), array([[ 25.39500046,  30.98800087],\n",
      "       [ 15.18000031,  20.49099922],\n",
      "       [  7.99539995,  11.99499989],\n",
      "       [ 16.69099998,  24.61800003],\n",
      "       [ 25.60400009,  32.30199814],\n",
      "       [ 12.        ,  17.29999924],\n",
      "       [  5.73769999,   7.        ],\n",
      "       [  7.10370016,  11.26099968],\n",
      "       [  8.38829994,  16.83499908],\n",
      "       [ 10.11499977,  16.05699921]], dtype=float32), array([[ 22.32614899,  29.73100853],\n",
      "       [ 11.60329628,  17.25259399],\n",
      "       [ 10.11791801,  17.03334236],\n",
      "       [ 21.55584145,  30.11194992],\n",
      "       [ 26.1774559 ,  35.34766388],\n",
      "       [  9.67421246,  14.78485966],\n",
      "       [ 15.9302969 ,  21.96829224],\n",
      "       [ 10.97653675,  16.11657333],\n",
      "       [ 14.63603973,  20.84116745],\n",
      "       [ 14.88921642,  21.46494293]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print net.session.run([net.tf_X,net.tf_Y, net.logits], feed_dict=feed_dict)\n",
    "#print \"X\", np.shape(tf_X), \"Y\", np.shape(tf_Y), \"logits\", np.shape(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# To see the tensorflow model you've built in tensorboard, run the following\n",
    "journalist = tf.summary.FileWriter(net.checkpoint_dir, graph=net.session.graph)\n",
    "journalist.flush()\n",
    "\n",
    "# Now enter the following command at the command line\n",
    "# > tensorboard --logdir 'saved_models'\n",
    "# (you may need to replace 'saved_models' with the path to the actual \n",
    "# net.checkpoint_dir you are using)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
